import os
import shutil
import pandas as pd

# ==============================
# üì¶ Importar m√≥dulos de la aplicaci√≥n
# ==============================
from app.application.data_service import run_etl
from app.application.nlp_service import ejecutar_nlp_pipeline
from app.application.social_module import load_dataset, compute_social_index
from app.application.visual_service import generar_todos_los_graficos

# ==============================
# üìÇ RUTAS BASE
# ==============================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DATA_DIR = os.path.join(BASE_DIR, "data")
INFRA_VISUALS = os.path.join(BASE_DIR, "app", "infrastructure", "visuals")
STATIC_DIR = os.path.join(BASE_DIR, "app", "api", "static")

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(INFRA_VISUALS, exist_ok=True)
os.makedirs(STATIC_DIR, exist_ok=True)

# ==============================
# üöÄ PIPELINE COMPLETO
# ==============================
def run_pipeline():
    print("üîÑ Iniciando pipeline completo de ComuniMind...\n")

    # -------------------------------------------------
    # 1Ô∏è‚É£ ETL: limpieza y normalizaci√≥n de datos
    # -------------------------------------------------
    print("üßπ Paso 1: Ejecutando limpieza de datos (ETL)...")
    run_etl()

    # -------------------------------------------------
    # 2Ô∏è‚É£ An√°lisis de temas y sentimientos (NLP)
    # -------------------------------------------------
    print("\nüß† Paso 2: Analizando temas y sentimientos...")
    ejecutar_nlp_pipeline()

    # -------------------------------------------------
    # 3Ô∏è‚É£ An√°lisis de vulnerabilidad e impacto social
    # -------------------------------------------------
    print("\nüåç Paso 3: Calculando vulnerabilidad e impacto social...")
    df = load_dataset(os.path.join(DATA_DIR, "clean_data.csv"))
    social_df = compute_social_index(df)
    impact_path = os.path.join(DATA_DIR, "impact_social.csv")
    social_df.to_csv(impact_path, sep=";", encoding="utf-8", index=False)
    print(f"üìÅ Archivo guardado: {impact_path}")

    # -------------------------------------------------
    # 4Ô∏è‚É£ Integrar resultados NLP + Social
    # -------------------------------------------------
    print("\nüîó Paso 4: Integrando resultados finales...")
    nlp_df = pd.read_csv(os.path.join(DATA_DIR, "themes_nlp.csv"), sep=";")

    merged = pd.merge(social_df, nlp_df, on="ciudad", how="left")
    merged_path = os.path.join(DATA_DIR, "final_results.csv")
    merged.to_csv(merged_path, sep=";", encoding="utf-8", index=False)
    print(f"‚úÖ Archivo unificado generado: {merged_path}")

    # -------------------------------------------------
    # 5Ô∏è‚É£ Generar visualizaciones finales
    # -------------------------------------------------
    print("\nüé® Paso 5: Generando visualizaciones sociales...")
    output_visuals = os.path.join(BASE_DIR, "app", "infrastructure", "visuals")
    rutas = generar_todos_los_graficos(output_visuals)
    print("‚úÖ Gr√°ficos generados:", rutas)
    # -------------------------------------------------
    # 6Ô∏è‚É£ Copiar visualizaciones a carpeta del dashboard
    # -------------------------------------------------
    print("\nüß± Paso 6: Actualizando dashboard...")
    for _, path in rutas.items():
        destino = os.path.join(STATIC_DIR, os.path.basename(path))
        shutil.copy2(path, destino)
    print(f"‚úÖ Gr√°ficos copiados a {STATIC_DIR}")

    # -------------------------------------------------
    # 7Ô∏è‚É£ Confirmar finalizaci√≥n
    # -------------------------------------------------
    print("\nüéØ Pipeline completado exitosamente.")
    print(f"üì¶ Resultados disponibles en: {DATA_DIR}")
    print(f"üñºÔ∏è Visualizaciones listas en: {STATIC_DIR}\n")


if __name__ == "__main__":
    run_pipeline()
